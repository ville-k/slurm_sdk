# Integration Test Design: Eliminating Wheel Dependency

## Problem Statement

Currently, integration tests build a wheel of `slurm-sdk` and upload it to the test Slurm cluster. This creates a critical dependency problem:

1. **Stale Code**: The wheel contains a snapshot of the code at build time, not the current working code
2. **Development Friction**: Changes to SDK code don't reflect in tests until wheel is rebuilt
3. **Nested Problem**: Workflows build wheels that submit child tasks, which use code from the wheel
   - Parent workflow wheel contains old SDK code
   - Child tasks generated by that old code also use old patterns
   - Fix requires 2-level propagation (rebuild wheel, then re-run parent to get new child behavior)
4. **Debugging Nightmare**: When tests fail, unclear if it's due to new code or stale wheel

### Current Flow
```
Test Run
  └─> Build wheel from current SDK code
      └─> Upload wheel to cluster
          └─> Submit job (uses wheel's SDK code)
              └─> Job runs workflow (uses wheel's SDK code)
                  └─> Workflow submits child tasks (uses wheel's SDK code)
                      └─> Child tasks run (use wheel's SDK code from parent)
```

**Problem**: Between "current SDK code" and actual execution, there are 3-4 layers of indirection through the wheel.

## Design Constraints

1. **Real Cluster Required**: Must test against actual Slurm (not mocks) for integration tests
2. **SSH Backend**: Tests use SSH to communicate with containerized Slurm cluster
3. **Nested Workflows**: Must support workflows that submit child tasks
4. **File Transfer**: Need mechanism to get SDK code to remote cluster
5. **Python Environment**: Remote cluster needs dependencies installed

## Proposed Solutions

### Option 1: Editable Install via SSH (Recommended)

**Concept**: Instead of building a wheel, sync the SDK source directory to the cluster and use `pip install -e` (editable mode).

**Architecture**:
```
Test Run
  └─> Rsync SDK source to cluster:/tmp/slurm_sdk_dev/
      └─> SSH: pip install -e /tmp/slurm_sdk_dev/
          └─> Set PYTHONPATH=/tmp/slurm_sdk_dev/src
              └─> Submit job (imports from /tmp/slurm_sdk_dev/src)
                  └─> Job runs workflow (imports from /tmp/slurm_sdk_dev/src)
                      └─> Child tasks (imports from /tmp/slurm_sdk_dev/src)
```

**Implementation**:
```python
# In conftest.py
@pytest.fixture(scope="session")
def sdk_on_cluster(slurm_container):
    """Sync SDK source to cluster for editable development."""
    runtime = slurm_container["runtime"]
    container = slurm_container["name"]

    # Get SDK root directory
    sdk_root = Path(__file__).resolve().parents[2]

    # Copy SDK source into container
    # Using podman/docker cp is faster than SSH for local containers
    subprocess.run([
        runtime, "cp",
        str(sdk_root),
        f"{container}:/tmp/slurm_sdk_dev"
    ], check=True)

    # Install in editable mode
    subprocess.run([
        runtime, "exec", container,
        "pip3.11", "install", "-e", "/tmp/slurm_sdk_dev"
    ], check=True)

    return "/tmp/slurm_sdk_dev"

# Update slurm_cluster fixture
@pytest.fixture
def slurm_cluster(slurm_cluster_config, sdk_on_cluster, tmp_path):
    # Change packaging config to use installed SDK
    config = slurm_cluster_config.copy()
    config["packaging"] = {
        "type": "none",  # Don't build/upload wheel
    }

    # SDK is already installed on cluster via editable install
    return Cluster.from_env(...)
```

**Pros**:
- ✅ Changes to SDK code immediately visible (just re-run test)
- ✅ No wheel build time
- ✅ Works for nested workflows (all import from same source)
- ✅ Matches developer expectations (edit → test → iterate)
- ✅ Simple to understand and maintain

**Cons**:
- ❌ Requires container runtime (podman/docker) access (but we already have this)
- ❌ Doesn't test wheel packaging itself (but that's a different concern)
- ❌ Need to sync dependencies separately

### Option 2: Source Directory Upload with PYTHONPATH

**Concept**: Upload raw source files via SSH and set PYTHONPATH, no install step.

**Architecture**:
```
Test Run
  └─> SSH: Upload src/ to /tmp/slurm_sdk_src/
      └─> Set PYTHONPATH=/tmp/slurm_sdk_src
          └─> Submit job (imports from PYTHONPATH)
```

**Implementation**:
```python
@pytest.fixture(scope="session")
def sdk_on_cluster(slurm_cluster, tmp_path):
    """Upload SDK source to cluster."""
    sdk_src = Path(__file__).resolve().parents[2] / "src"
    remote_path = "/tmp/slurm_sdk_src"

    # Upload via SFTP
    sftp = slurm_cluster.backend.sftp_client
    sftp.mkdir(remote_path)

    # Upload all .py files
    for py_file in sdk_src.rglob("*.py"):
        rel_path = py_file.relative_to(sdk_src)
        remote_file = f"{remote_path}/{rel_path}"
        # Create parent dirs
        sftp.makedirs(os.path.dirname(remote_file))
        sftp.put(str(py_file), remote_file)

    # Set PYTHONPATH in job script
    return remote_path

# Modify rendering.py to include:
script_lines.append(f"export PYTHONPATH={sdk_path}:$PYTHONPATH")
```

**Pros**:
- ✅ No installation required
- ✅ Fast sync (only .py files)
- ✅ Changes immediately visible

**Cons**:
- ❌ Doesn't install dependencies
- ❌ More complex PYTHONPATH management
- ❌ Doesn't handle C extensions or compiled code
- ❌ May miss package metadata

### Option 3: Hybrid - Editable Install + Hot Reload

**Concept**: Editable install for dependencies, but sync source before each test.

**Architecture**:
```
Session Setup
  └─> Install SDK in editable mode (one-time)
      └─> Install dependencies

Each Test
  └─> Rsync only src/ directory
      └─> Run test (uses updated source)
```

**Implementation**:
```python
@pytest.fixture(scope="session")
def sdk_installed(slurm_container):
    """One-time SDK installation."""
    # ... editable install ...

@pytest.fixture
def sdk_synced(slurm_container, sdk_installed):
    """Per-test source sync."""
    sdk_src = Path(__file__).resolve().parents[2] / "src"
    # Fast rsync only changed files
    subprocess.run([
        "rsync", "-az", "--delete",
        str(sdk_src) + "/",
        f"{container}:/tmp/slurm_sdk_dev/src/"
    ])
```

**Pros**:
- ✅ Best of both worlds
- ✅ Dependencies installed once
- ✅ Source synced per test (very fast with rsync)

**Cons**:
- ❌ More complex setup
- ❌ Requires rsync

### Option 4: Local Backend Only (Test Simplification)

**Concept**: Use LocalCommandBackend for integration tests, eliminate SSH entirely.

**Architecture**:
```
Test Run (all local)
  └─> Cluster with local backend
      └─> Jobs run in-process
          └─> Uses current Python environment
              └─> Immediate code changes
```

**Implementation**:
```python
@pytest.fixture
def slurm_cluster():
    """Local cluster for fast iteration."""
    from slurm.cluster import Cluster
    return Cluster(
        backend=LocalCommandBackend(),
        callbacks=[]
    )
```

**Pros**:
- ✅ Simplest possible solution
- ✅ Instant feedback
- ✅ No container overhead
- ✅ Perfect for rapid development

**Cons**:
- ❌ Doesn't test real Slurm integration
- ❌ Doesn't test SSH backend
- ❌ Doesn't test wheel packaging
- ❌ Different execution path than production

## Recommended Approach

**Two-Tier Testing Strategy**:

### Tier 1: Fast Development Tests (Local Backend)
- Use `LocalCommandBackend` for rapid iteration
- Mark with `@pytest.mark.unit` or `@pytest.mark.fast`
- Run on every code change
- Test workflow logic, callbacks, API

### Tier 2: True Integration Tests (Editable Install)
- Use Option 1 (Editable Install via SSH)
- Mark with `@pytest.mark.integration` and `@pytest.mark.slow`
- Run before commits or in CI
- Test actual Slurm integration, SSH backend, cluster behavior

**Configuration**:
```python
# conftest.py
@pytest.fixture
def cluster_mode(request):
    """Determine cluster mode from pytest markers."""
    if request.node.get_closest_marker("integration"):
        return "remote"  # Use container with editable install
    return "local"  # Use LocalCommandBackend

@pytest.fixture
def slurm_cluster(cluster_mode, slurm_container, sdk_on_cluster):
    if cluster_mode == "local":
        return Cluster(backend=LocalCommandBackend())

    # Remote mode with editable install
    config = {
        "packaging": {"type": "none"},  # SDK already installed
        ...
    }
    return Cluster.from_env(config)
```

## Implementation Plan

### Phase 1: Add Local Backend Tests (Immediate)
1. Create `tests/fast/` directory for local backend tests
2. Move workflow callback tests to fast tests
3. Use `LocalCommandBackend` for instant feedback
4. Keep existing integration tests as-is

### Phase 2: Implement Editable Install (Next)
1. Add `sdk_on_cluster` fixture to `conftest.py`
2. Update `slurm_cluster` fixture to support "none" packaging
3. Modify integration tests to use editable install
4. Add documentation

### Phase 3: Optimize (Future)
1. Add rsync-based hot reload for even faster iteration
2. Cache container state between test runs
3. Parallel test execution

## Testing the Tests

How to verify the solution works:

```python
# Test that changes are reflected immediately
def test_immediate_reflection(slurm_cluster):
    """Verify SDK changes are visible without rebuild."""
    # 1. Submit job that prints SDK version
    # 2. Modify SDK code to change version string
    # 3. Submit another job
    # 4. Verify new version is printed (without rebuild)
```

## Migration Path

**Backward Compatibility**: Keep existing wheel-based tests working:

```python
@pytest.fixture
def slurm_cluster(request, cluster_config):
    # Check for marker to use old wheel-based approach
    if request.node.get_closest_marker("wheel_packaging"):
        return cluster_with_wheel_packaging(cluster_config)

    # Default to editable install
    return cluster_with_editable_install(cluster_config)
```

This allows gradual migration and ensures wheel packaging tests still exist for the packaging feature itself.

## Conclusion

**Recommendation**: Implement Option 1 (Editable Install) for integration tests, supplemented with local backend tests for rapid development.

**Benefits**:
- Development velocity: Edit → Test in seconds instead of minutes
- Reliability: Test actual code, not stale snapshots
- Debuggability: Clear connection between code and test behavior
- Maintainability: Simpler mental model

**Next Steps**:
1. Implement `sdk_on_cluster` fixture
2. Update `slurm_cluster` fixture to use "none" packaging
3. Verify workflow tests pass with editable install
4. Document in README
